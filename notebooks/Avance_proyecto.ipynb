{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":98152,"status":"ok","timestamp":1682801062056,"user":{"displayName":"Michael rivera","userId":"11271803176980018053"},"user_tz":300},"id":"LBpwuHJlH8Ap","outputId":"271def54-aeef-4144-fc24-cf0a6c7fe976"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pandas_path\n","  Downloading pandas_path-0.3.0-py3-none-any.whl (8.4 kB)\n","Requirement already satisfied: pandas>=0.23 in /usr/local/lib/python3.10/dist-packages (from pandas_path) (1.5.3)\n","Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23->pandas_path) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23->pandas_path) (2022.7.1)\n","Requirement already satisfied: numpy>=1.21.0 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.23->pandas_path) (1.22.4)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas>=0.23->pandas_path) (1.16.0)\n","Installing collected packages: pandas_path\n","Successfully installed pandas_path-0.3.0\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting fasttext\n","  Downloading fasttext-0.9.2.tar.gz (68 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m68.8/68.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Collecting pybind11>=2.2\n","  Using cached pybind11-2.10.4-py3-none-any.whl (222 kB)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.22.4)\n","Building wheels for collected packages: fasttext\n","  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4393315 sha256=e34b174fcf297c5ae8e2a499af5b0084f4e73f679c1eb97d2452899858c6e438\n","  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n","Successfully built fasttext\n","Installing collected packages: pybind11, fasttext\n","Successfully installed fasttext-0.9.2 pybind11-2.10.4\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting pytorch_lightning\n","  Downloading pytorch_lightning-2.0.2-py3-none-any.whl (719 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m719.0/719.0 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.65.0)\n","Collecting lightning-utilities>=0.7.0\n","  Downloading lightning_utilities-0.8.0-py3-none-any.whl (20 kB)\n","Requirement already satisfied: fsspec[http]>2021.06.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (4.5.0)\n","Requirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (6.0)\n","Requirement already satisfied: torch>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (2.0.0+cu118)\n","Requirement already satisfied: packaging>=17.1 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (23.1)\n","Collecting torchmetrics>=0.7.0\n","  Downloading torchmetrics-0.11.4-py3-none-any.whl (519 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m519.2/519.2 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.10/dist-packages (from pytorch_lightning) (1.22.4)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>2021.06.0->pytorch_lightning) (2.27.1)\n","Collecting aiohttp!=4.0.0a0,!=4.0.0a1\n","  Downloading aiohttp-3.8.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m69.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (1.11.1)\n","Requirement already satisfied: triton==2.0.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (2.0.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (3.1)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (3.1.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.11.0->pytorch_lightning) (3.12.0)\n","Requirement already satisfied: cmake in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch_lightning) (3.25.2)\n","Requirement already satisfied: lit in /usr/local/lib/python3.10/dist-packages (from triton==2.0.0->torch>=1.11.0->pytorch_lightning) (16.0.2)\n","Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (2.0.12)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>2021.06.0->pytorch_lightning) (23.1.0)\n","Collecting aiosignal>=1.1.2\n","  Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n","Collecting multidict<7.0,>=4.5\n","  Downloading multidict-6.0.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (114 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.5/114.5 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting frozenlist>=1.1.1\n","  Downloading frozenlist-1.3.3-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (149 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.6/149.6 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting async-timeout<5.0,>=4.0.0a3\n","  Downloading async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\n","Collecting yarl<2.0,>=1.0\n","  Downloading yarl-1.9.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (268 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m268.8/268.8 kB\u001b[0m \u001b[31m25.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.11.0->pytorch_lightning) (2.1.2)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->fsspec[http]>2021.06.0->pytorch_lightning) (3.4)\n","Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.11.0->pytorch_lightning) (1.3.0)\n","Installing collected packages: multidict, lightning-utilities, frozenlist, async-timeout, yarl, aiosignal, aiohttp, torchmetrics, pytorch_lightning\n","Successfully installed aiohttp-3.8.4 aiosignal-1.3.1 async-timeout-4.0.2 frozenlist-1.3.3 lightning-utilities-0.8.0 multidict-6.0.4 pytorch_lightning-2.0.2 torchmetrics-0.11.4 yarl-1.9.2\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting transformers\n","  Downloading transformers-4.28.1-py3-none-any.whl (7.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.0/7.0 MB\u001b[0m \u001b[31m52.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1\n","  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n","Collecting huggingface-hub<1.0,>=0.11.0\n","  Downloading huggingface_hub-0.14.1-py3-none-any.whl (224 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m224.5/224.5 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (2023.4.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.11.0->transformers) (4.5.0)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.15)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2022.12.7)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n","Installing collected packages: tokenizers, huggingface-hub, transformers\n","Successfully installed huggingface-hub-0.14.1 tokenizers-0.13.3 transformers-4.28.1\n"]}],"source":["!pip install pandas_path\n","!pip install fasttext\n","!pip install pytorch_lightning\n","!pip install transformers"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"79DvXU77HR54","executionInfo":{"status":"ok","timestamp":1682801071628,"user_tz":300,"elapsed":9592,"user":{"displayName":"Michael rivera","userId":"11271803176980018053"}}},"outputs":[],"source":["%matplotlib inline\n","\n","import json\n","import logging\n","from pathlib import Path\n","import random\n","import tarfile\n","import tempfile\n","import warnings\n","import os\n","from PIL import Image\n","\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import pandas as pd\n","import pandas_path  # Path style access for pandas\n","from tqdm import tqdm\n","\n","import torch                    \n","import torchvision\n","import fasttext\n","import pytorch_lightning\n","from torch.utils.data import DataLoader, random_split\n","import torchvision.models as models\n","from transformers import BertModel\n","from transformers import BertTokenizer\n","from transformers import RobertaModel\n","from transformers import DistilBertModel\n","from transformers import RobertaTokenizer\n","from transformers import DistilBertTokenizer\n","import torch.optim as optim\n"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":29947,"status":"ok","timestamp":1682801101520,"user":{"displayName":"Michael rivera","userId":"11271803176980018053"},"user_tz":300},"id":"5rDm12HtKeTY","outputId":"940aff31-6f64-43e0-b9fc-50a59700f9c4"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"HTb74UEvKfPH","executionInfo":{"status":"ok","timestamp":1682801101522,"user_tz":300,"elapsed":21,"user":{"displayName":"Michael rivera","userId":"11271803176980018053"}}},"outputs":[],"source":["project_directory = '/content/drive/MyDrive/HatefulMemes'\n","os.chdir(project_directory)"]},{"cell_type":"code","execution_count":5,"metadata":{"id":"LptlZPCLJ9TW","executionInfo":{"status":"ok","timestamp":1682801101524,"user_tz":300,"elapsed":18,"user":{"displayName":"Michael rivera","userId":"11271803176980018053"}}},"outputs":[],"source":["data_dir = Path.cwd()\n","\n","train_path = \"train.jsonl\"\n","dev_path = \"dev.jsonl\"\n","test_path = \"test.jsonl\""]},{"cell_type":"markdown","metadata":{"id":"j_XqTl-qG0Fu"},"source":["## Baseline:\n","\n","This first experiment performs a mid-level concat fusion between a RESNET50 and a FCC over a fasttext embedding\n","\n","\n","\n","*   Lr = 1e-4 Train Loss: 0.4472, Train Accuracy: 0.8631, Val Loss: 0.7825, Val Accuracy: 0.5100\n","*   Lr = 1e-5 Train Loss: 0.3442, Train Accuracy: 0.9691, Val Loss: 0.7883, Val Accuracy: 0.5060\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"OnWTabP5N4kM"},"outputs":[],"source":["class HatefulMemesDataset(torch.utils.data.Dataset):\n","    \"\"\"Uses jsonl data to preprocess and serve \n","    dictionary of multimodal tensors for model input.\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        data_path,\n","        img_dir,\n","        image_transform,\n","        text_transform,\n","        balance=False,\n","        dev_limit=None,\n","        random_state=0,\n","    ):\n","\n","        self.samples_frame = pd.read_json(\n","            data_path, lines=True\n","        )\n","        self.dev_limit = dev_limit\n","        if balance:\n","            neg = self.samples_frame[\n","                self.samples_frame.label.eq(0)\n","            ]\n","            pos = self.samples_frame[\n","                self.samples_frame.label.eq(1)\n","            ]\n","            self.samples_frame = pd.concat(\n","                [\n","                    neg.sample(\n","                        pos.shape[0], \n","                        random_state=random_state\n","                    ), \n","                    pos\n","                ]\n","            )\n","        if self.dev_limit:\n","            if self.samples_frame.shape[0] > self.dev_limit:\n","                self.samples_frame = self.samples_frame.sample(\n","                    dev_limit, random_state=random_state\n","                )\n","        self.samples_frame = self.samples_frame.reset_index(\n","            drop=True\n","        )\n","        self.samples_frame.img = self.samples_frame.apply(\n","            lambda row: (img_dir / row.img), axis=1\n","        )\n","\n","        # https://github.com/drivendataorg/pandas-path\n","        for path in self.samples_frame.img:\n","            if not path.exists():\n","                raise FileNotFoundError(f'{path} doesnt seem to exist')\n","            if not path.is_file():\n","                raise TypeError(f'{path} doesnt seem to be a file')\n","            \n","        self.image_transform = image_transform\n","        self.text_transform = text_transform\n","\n","    def __len__(self):\n","        \"\"\"This method is called when you do len(instance) \n","        for an instance of this class.\n","        \"\"\"\n","        return len(self.samples_frame)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"This method is called when you do instance[key] \n","        for an instance of this class.\n","        \"\"\"\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        img_id = self.samples_frame.loc[idx, \"id\"]\n","\n","        image = Image.open(\n","            self.samples_frame.loc[idx, \"img\"]\n","        ).convert(\"RGB\")\n","        image = self.image_transform(image)\n","\n","        text = torch.Tensor(\n","            self.text_transform.get_sentence_vector(\n","                self.samples_frame.loc[idx, \"text\"]\n","            )\n","        ).squeeze()\n","\n","        if \"label\" in self.samples_frame.columns:\n","            label = torch.Tensor(\n","                [self.samples_frame.loc[idx, \"label\"]]\n","            ).long().squeeze()\n","            sample = {\n","                \"id\": img_id, \n","                \"image\": image, \n","                \"text\": text, \n","                \"label\": label\n","            }\n","        else:\n","            sample = {\n","                \"id\": img_id, \n","                \"image\": image, \n","                \"text\": text\n","            }\n","\n","        return sample"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ibQs3TaAOoI"},"outputs":[],"source":["def _build_text_transform(train_path, fasttext_model='cbow', embedding_dim=100):\n","    with tempfile.NamedTemporaryFile() as ft_training_data:\n","        ft_path = Path(ft_training_data.name)\n","        with ft_path.open(\"w\") as ft:\n","            training_data = [\n","                json.loads(line)[\"text\"] + \"/n\" \n","                for line in open(train_path).read().splitlines()\n","            ]\n","            for line in training_data:\n","                ft.write(line + \"\\n\")\n","            language_transform = fasttext.train_unsupervised(\n","                str(ft_path),\n","                model=fasttext_model,\n","                dim=embedding_dim\n","            )\n","    return language_transform\n","\n","def _build_image_transform(image_dim=224):\n","    image_transform = torchvision.transforms.Compose(\n","        [\n","            torchvision.transforms.Resize(\n","                size=(image_dim, image_dim)\n","            ),        \n","            torchvision.transforms.ToTensor(),\n","            # all torchvision models expect the same\n","            # normalization mean and std\n","            # https://pytorch.org/docs/stable/torchvision/models.html\n","            torchvision.transforms.Normalize(\n","                mean=(0.485, 0.456, 0.406), \n","                std=(0.229, 0.224, 0.225)\n","            ),\n","        ]\n","    )\n","    return image_transform"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KBGdSrRkAQnA"},"outputs":[],"source":["text_transform = _build_text_transform('train.jsonl')\n","image_transform = _build_image_transform()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_7UCE6RdAiy5"},"outputs":[],"source":["dataset = HatefulMemesDataset(\n","    data_path='train.jsonl',\n","    img_dir=Path('.'),\n","    image_transform=image_transform,\n","    text_transform=text_transform,\n","    balance=False,\n","    dev_limit=None,\n","    random_state=0,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4kixrDGDE1N8"},"outputs":[],"source":["class LanguageAndVisionConcat(torch.nn.Module):\n","    def __init__(\n","        self,\n","        num_classes,\n","        loss_fn,\n","        language_module,\n","        vision_module,\n","        language_feature_dim,\n","        vision_feature_dim,\n","        fusion_output_size,\n","        dropout_p,\n","        \n","    ):\n","        super(LanguageAndVisionConcat, self).__init__()\n","        self.language_module = language_module\n","        self.vision_module = vision_module\n","        self.fusion = torch.nn.Linear(\n","            in_features=(language_feature_dim + vision_feature_dim), \n","            out_features=fusion_output_size\n","        )\n","        self.fc = torch.nn.Linear(\n","            in_features=fusion_output_size, \n","            out_features=num_classes\n","        )\n","        self.loss_fn = loss_fn\n","        self.dropout = torch.nn.Dropout(dropout_p)\n","        \n","    def forward(self, text, image, label=None):\n","        text_features = torch.nn.functional.relu(\n","            self.language_module(text)\n","        )\n","        image_features = torch.nn.functional.relu(\n","            self.vision_module(image)\n","        )\n","        combined = torch.cat(\n","            [text_features, image_features], dim=1\n","        )\n","\n","        fused = self.dropout(\n","            torch.nn.functional.relu(\n","            self.fusion(combined)\n","            )\n","        )\n","        logits = self.fc(fused)\n","        pred = torch.nn.functional.softmax(logits)\n","        loss = (\n","            self.loss_fn(pred, label) \n","            if label is not None else label\n","        )\n","        return (pred, loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":522},"executionInfo":{"elapsed":87732,"status":"error","timestamp":1682719929796,"user":{"displayName":"Michael rivera","userId":"11271803176980018053"},"user_tz":300},"id":"RFgEh7WYrTmB","outputId":"103f253b-ce8e-42b6-805c-4a88261a41be"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","  0%|          | 0/266 [00:00<?, ?it/s]<ipython-input-10-5cc8ee081446>:45: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  pred = torch.nn.functional.softmax(logits)\n","  8%|▊         | 20/266 [01:23<17:01,  4.15s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-11-6006d229a252>\u001b[0m in \u001b[0;36m<cell line: 74>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[0mtrain_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["params = {\n","    \"lr\": 1e-5, \n","    \"batch_size\": 32,\n","    \"num_epochs\": 10,\n","    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n","    \"balance\": False,\n","    \"dev_limit\": None,\n","    \"random_state\": 0,\n","    \"dropout\": 0.2}\n","\n","\n","balance = params[\"balance\"]\n","dev_limit = params[\"dev_limit\"]\n","random_state = params[\"random_state\"]\n","batch_size = params[\"batch_size\"]\n","num_epochs = params[\"num_epochs\"]\n","lr = params[\"lr\"]\n","device = params[\"device\"]\n","dropout = params[\"dropout\"]\n","language_feature_dim = 300\n","\n","training_data = HatefulMemesDataset(data_path=train_path,\n","    img_dir=Path('.'),\n","    image_transform=image_transform,\n","    text_transform=text_transform,\n","    balance= balance,\n","    dev_limit= dev_limit,\n","    random_state= random_state)\n","\n","validation_data = HatefulMemesDataset(data_path=dev_path,\n","    img_dir=Path('.'),\n","    image_transform=image_transform,\n","    text_transform=text_transform,\n","    balance = balance,\n","    dev_limit= dev_limit,\n","    random_state= random_state)\n","\n","train_loader = DataLoader(training_data,\n","                          batch_size = batch_size,\n","                          shuffle= True,\n","                          num_workers = 2)\n","\n","test_loader = DataLoader(validation_data,\n","                          batch_size = batch_size,\n","                          shuffle=True,\n","                          num_workers = 2)\n","\n","#text_model = BertModel.from_pretrained('bert-base-uncased')\n","text_model = torch.nn.Linear(\n","                in_features= 100,\n","                out_features= language_feature_dim\n","        )\n","vision_model = models.resnet50(pretrained=True)\n","\n","model = LanguageAndVisionConcat(\n","    num_classes = 2,\n","    loss_fn = torch.nn.CrossEntropyLoss(),\n","    language_module = text_model,\n","    vision_module = vision_model,\n","    language_feature_dim = language_feature_dim,\n","    vision_feature_dim = 1000,\n","    fusion_output_size = 512,\n","    dropout_p = 0.1\n",").to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","    optimizer, mode='max', factor=0.5, patience=2, verbose=True\n",")\n","\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","best_val_acc = 0.0\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_loss = 0.0\n","    train_correct = 0\n","    for idx, batch in tqdm(enumerate(train_loader), total = len(train_loader)):\n","        images = batch[\"image\"].to(device)\n","        texts = batch[\"text\"].to(device)\n","        labels = batch[\"label\"].to(device)\n","        optimizer.zero_grad()\n","        outputs, loss = model(texts, images, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item() * images.size(0)\n","        train_correct += torch.sum(torch.argmax(outputs, dim=1) == labels)\n","\n","    train_loss /= len(train_loader.dataset)\n","    train_accuracy = train_correct.float() / len(train_loader.dataset)\n","\n","    model.eval()\n","\n","    val_loss = 0.0\n","    val_correct = 0\n","\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            images = batch[\"image\"].to(device)\n","            texts = batch[\"text\"].to(device)\n","            labels = batch[\"label\"].to(device)\n","            outputs, loss = model(texts, images, labels)\n","            val_loss += loss.item() * images.size(0)\n","            val_correct += torch.sum(torch.argmax(outputs, dim=1) == labels)\n","\n","    val_loss /= len(test_loader.dataset)\n","    val_accuracy = val_correct.float() / len(test_loader.dataset)\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n","  \n","\n"]},{"cell_type":"markdown","metadata":{"id":"zs6MP0vMoOOw"},"source":["## Experiment 1:\n","\n","Let's use a BERT model to process text while keeping the same resnet50\n","\n","- Lr = 1e-5 dropout = 0.2 FC_length = 250, Train Accuracy: 0.9682, Val Loss: 0.7317, Val Accuracy: 0.5700\n","- Lr = 1e-5 dropout = 0.2 FC_length = 50, Train Loss: 0.3419, Train Accuracy: 0.9740, Val Loss: 0.7518, Val Accuracy: 0.5400\n","- Lr = 1e-7 dropout = 0.2 FC_length = 50, Train Loss: 0.6517, Train Accuracy: 0.6382, Val Loss: 0.7157, Val Accuracy: 0.5040\n","- Lr = 1e-5 dropout = 0.2 FC_length = 50, batch_size = 64, +normalization_layer Train Loss: 0.3574, Train Accuracy: 0.9818, Val Loss: 0.7028, Val Accuracy: 0.5740"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1129,"status":"ok","timestamp":1682719938385,"user":{"displayName":"Michael rivera","userId":"11271803176980018053"},"user_tz":300},"id":"ZW2hssQAoqFr","colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["b1f8b1b206e64aa0ac76f981fb054d7b","538f70f847ba4693b9d1955b9cabae95","d8f72d85ddbd4f1fb778d69b7feff2de","ef252daef8c8403c87013e7e9471a2dc","ac37a2ff350042bfbb8237e50b398366","60bca1b8b3154f92a083602fdc892d9d","c89061a97b4e420890730fc334ff1db4","f09607aa9b6e4b629274ededa07cac9d","fc0b55a4565d4f5fbacfebd69be8ea95","8e4f2cbd71874a168081b66f181a9547","57eab05385e4479384979dc772514e7a","b823574261e74f4fbcee9ffa99bca7e3","295bbbe656544415962050c71dffc7f2","a17beec42cd54e21b2ea78db7dbde672","011fa4e606ae4c4bb54edac674ce06ac","bce83093ebff4ea09d4fa059aa4c0550","b44f17bbfcb94e5da8d24ca845c5c9b4","eee11cb6a4664b94b8097a46a2a79dbe","7b3c866abb5847579852ba1bac610c20","2d7893dc076440d6984eca4565e2f6a8","63820311ddba46058a21e38b3ec2411f","ef8368aee1934a319d9bec718697a2be","6081c5f0abb245659673f76827e89335","5942abd915684efbbc317dcd56159276","163f33b9b652436cb1ce899769c08b53","d4fa19cb85924248b7ad6f814d7b77d0","b27194c970094cd48848450e22592118","5075c618026c40a0b3b520d249a6df72","8244378f753941a4ad8fb6c504ad819e","ca98ba6ccab74f33bdbe1c3a742854ba","5e38db9951074f89969fac7b1c25069b","f22997b7add54b3d86a2bf64808a4b8a","48d0ff28190041408f623a174818f5d6"]},"outputId":"09664c0e-bac3-4500-c1b0-9180c334d90f"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b1f8b1b206e64aa0ac76f981fb054d7b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b823574261e74f4fbcee9ffa99bca7e3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6081c5f0abb245659673f76827e89335"}},"metadata":{}}],"source":["from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","\n","def _build_image_transform(image_dim=224):\n","    image_transform = torchvision.transforms.Compose(\n","        [\n","            torchvision.transforms.Resize(\n","                size=(image_dim, image_dim)\n","            ),        \n","            torchvision.transforms.ToTensor(),\n","            # all torchvision models expect the same\n","            # normalization mean and std\n","            # https://pytorch.org/docs/stable/torchvision/models.html\n","            torchvision.transforms.Normalize(\n","                mean=(0.485, 0.456, 0.406), \n","                std=(0.229, 0.224, 0.225)\n","            ),\n","        ]\n","    )\n","    return image_transform\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jlTqGdKq6KOG"},"outputs":[],"source":["text_transform = tokenizer\n","image_transform = _build_image_transform()"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"biBDEInc2cWH"},"outputs":[],"source":["class HatefulMemesDataset(torch.utils.data.Dataset):\n","    \"\"\"Uses jsonl data to preprocess and serve \n","    dictionary of multimodal tensors for model input.\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        data_path,\n","        img_dir,\n","        image_transform,\n","        text_transform,\n","        balance=False,\n","        dev_limit=None,\n","        random_state=0,\n","    ):\n","\n","        self.samples_frame = pd.read_json(\n","            data_path, lines=True\n","        )\n","        self.dev_limit = dev_limit\n","        if balance:\n","            neg = self.samples_frame[\n","                self.samples_frame.label.eq(0)\n","            ]\n","            pos = self.samples_frame[\n","                self.samples_frame.label.eq(1)\n","            ]\n","            self.samples_frame = pd.concat(\n","                [\n","                    neg.sample(\n","                        pos.shape[0], \n","                        random_state=random_state\n","                    ), \n","                    pos\n","                ]\n","            )\n","        if self.dev_limit:\n","            if self.samples_frame.shape[0] > self.dev_limit:\n","                self.samples_frame = self.samples_frame.sample(\n","                    dev_limit, random_state=random_state\n","                )\n","        self.samples_frame = self.samples_frame.reset_index(\n","            drop=True\n","        )\n","        self.samples_frame.img = self.samples_frame.apply(\n","            lambda row: (img_dir / row.img), axis=1\n","        )\n","\n","        # https://github.com/drivendataorg/pandas-path\n","        for path in self.samples_frame.img:\n","            if not path.exists():\n","                raise FileNotFoundError(f'{path} doesnt seem to exist')\n","            if not path.is_file():\n","                raise TypeError(f'{path} doesnt seem to be a file')\n","            \n","        self.image_transform = image_transform\n","        self.text_transform = text_transform\n","\n","    def __len__(self):\n","        \"\"\"This method is called when you do len(instance) \n","        for an instance of this class.\n","        \"\"\"\n","        return len(self.samples_frame)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"This method is called when you do instance[key] \n","        for an instance of this class.\n","        \"\"\"\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        img_id = self.samples_frame.loc[idx, \"id\"]\n","\n","        image = Image.open(\n","            self.samples_frame.loc[idx, \"img\"]\n","        ).convert(\"RGB\")\n","        image = self.image_transform(image)\n","\n","        text = torch.Tensor(\n","            self.text_transform(\n","                self.samples_frame.loc[idx, \"text\"],\n","                max_length=20,\n","                padding='max_length',\n","                truncation=True, \n","                return_tensors=\"pt\"\n","            ).input_ids\n","        ).squeeze()\n","\n","        if \"label\" in self.samples_frame.columns:\n","            label = torch.Tensor(\n","                [self.samples_frame.loc[idx, \"label\"]]\n","            ).long().squeeze()\n","            sample = {\n","                \"id\": img_id, \n","                \"image\": image, \n","                \"text\": text, \n","                \"label\": label\n","            }\n","        else:\n","            sample = {\n","                \"id\": img_id, \n","                \"image\": image, \n","                \"text\": text\n","            }\n","\n","        return sample"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6fgDF2YLxUHT"},"outputs":[],"source":["class LanguageAndVisionConcat(torch.nn.Module):\n","    def __init__(\n","        self,\n","        num_classes,\n","        loss_fn,\n","        language_module,\n","        vision_module,\n","        language_feature_dim,\n","        vision_feature_dim,\n","        fusion_output_size,\n","        dropout_p,\n","        \n","    ):\n","        super(LanguageAndVisionConcat, self).__init__()\n","        self.language_module = language_module\n","        self.vision_module = vision_module\n","        self.fusion = torch.nn.Linear(\n","            in_features=(language_feature_dim + vision_feature_dim), \n","            out_features=fusion_output_size\n","        )\n","        self.norm = torch.nn.BatchNorm1d(fusion_output_size)\n","        self.fc = torch.nn.Linear(\n","            in_features=fusion_output_size, \n","            out_features=num_classes\n","        )\n","        self.loss_fn = loss_fn\n","        self.dropout = torch.nn.Dropout(dropout_p)\n","        \n","    def forward(self, text, image, label=None):\n","\n","        text_features = torch.nn.functional.relu(\n","            self.language_module(text).last_hidden_state.mean(dim=1)\n","        )\n","        image_features = torch.nn.functional.relu(\n","            self.vision_module(image)\n","        )\n","        combined = torch.cat(\n","            [text_features, image_features], dim=1\n","        )\n","\n","        fused = self.dropout(\n","            torch.nn.functional.relu(\n","            self.fusion(combined)\n","            )\n","        )\n","        normalized = self.norm(fused)\n","        logits = self.fc(normalized)\n","        pred = torch.nn.functional.softmax(logits)\n","        loss = (\n","            self.loss_fn(pred, label) \n","            if label is not None else label\n","        )\n","        return (pred, loss)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":606,"referenced_widgets":["8d34cf6df5a44eb7b251bc5f89e73de2","ce75700da8fd49bea41eba531a6734a2","f1eb0406447742429e5f9316b837ce13","0eb1c9cec8e1497c93ae7e9ac3fa84bf","026c2293cd2e421a892d04e546296f23","d240da6dd931453f825cd9a0bb8f4dd2","ee5d9610fe5844458b716041d0a77672","d39caea044ea451f8d9349c66fcca09e","66479f687cd7452db62a59e553ef8e33","fd66c47294ad4ae3a66c820a134a235c","5bd8095b743e40a895da8d98f4d15491"]},"executionInfo":{"elapsed":35604,"status":"error","timestamp":1682719973978,"user":{"displayName":"Michael rivera","userId":"11271803176980018053"},"user_tz":300},"id":"BaEhnkBz3edU","outputId":"d6a705d0-2bdc-47ad-c882-fe731fe077b0"},"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading pytorch_model.bin:   0%|          | 0.00/440M [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8d34cf6df5a44eb7b251bc5f89e73de2"}},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","  0%|          | 0/133 [00:00<?, ?it/s]<ipython-input-15-fd37cf7afe4a>:48: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  pred = torch.nn.functional.softmax(logits)\n","  2%|▏         | 2/133 [00:27<30:15, 13.86s/it]\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-16-36315b9c9f1a>\u001b[0m in \u001b[0;36m<cell line: 73>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     75\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m     \u001b[0mtrain_correct\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtotal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m         \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0mtexts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1178\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1179\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    632\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1327\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1328\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_shutdown\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m             \u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_tasks_outstanding\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_get_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1293\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1294\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1295\u001b[0;31m                 \u001b[0msuccess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_try_get_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1296\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msuccess\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1297\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_try_get_data\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1131\u001b[0m         \u001b[0;31m#   (bool: whether successfully get data, any: data if successful else None)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_data_queue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/queues.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m    111\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m                     \u001b[0mtimeout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdeadline\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmonotonic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    114\u001b[0m                         \u001b[0;32mraise\u001b[0m \u001b[0mEmpty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                 \u001b[0;32melif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mpoll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_poll\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    422\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_poll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 424\u001b[0;31m         \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    425\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    426\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/multiprocessing/connection.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    929\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    930\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 931\u001b[0;31m                 \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mselector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    933\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfileobj\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevents\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/lib/python3.10/selectors.py\u001b[0m in \u001b[0;36mselect\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m         \u001b[0mready\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfd_event_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selector\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpoll\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mInterruptedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mready\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["params = {\n","    \"lr\": 1e-5, \n","    \"batch_size\": 64,\n","    \"num_epochs\": 10,\n","    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n","    \"balance\": False,\n","    \"dev_limit\": None,\n","    \"random_state\": 0,\n","    \"dropout\": 0.2,\n","    \"fusion_output_size\": 50}\n","\n","\n","balance = params[\"balance\"]\n","dev_limit = params[\"dev_limit\"]\n","random_state = params[\"random_state\"]\n","batch_size = params[\"batch_size\"]\n","num_epochs = params[\"num_epochs\"]\n","lr = params[\"lr\"]\n","device = params[\"device\"]\n","dropout = params[\"dropout\"]\n","fusion_output_size = params[\"fusion_output_size\"]\n","language_feature_dim = 768\n","\n","\n","training_data = HatefulMemesDataset(data_path=train_path,\n","    img_dir=Path('.'),\n","    image_transform=image_transform,\n","    text_transform=text_transform,\n","    balance= balance,\n","    dev_limit= dev_limit,\n","    random_state= random_state)\n","\n","validation_data = HatefulMemesDataset(data_path=dev_path,\n","    img_dir=Path('.'),\n","    image_transform=image_transform,\n","    text_transform=text_transform,\n","    balance= balance,\n","    dev_limit= dev_limit,\n","    random_state= random_state)\n","\n","train_loader = DataLoader(training_data,\n","                          batch_size = batch_size,\n","                          shuffle= True,\n","                          num_workers = 2)\n","\n","test_loader = DataLoader(validation_data,\n","                          batch_size = batch_size,\n","                          shuffle=True,\n","                          num_workers = 2)\n","\n","text_model = BertModel.from_pretrained('bert-base-uncased')\n","vision_model = models.resnet50(pretrained=True)\n","\n","model = LanguageAndVisionConcat(\n","    num_classes = 2,\n","    loss_fn = torch.nn.CrossEntropyLoss(),\n","    language_module = text_model,\n","    vision_module = vision_model,\n","    language_feature_dim = language_feature_dim,\n","    vision_feature_dim = 1000,\n","    fusion_output_size = fusion_output_size,\n","    dropout_p = 0.1\n",").to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","    optimizer, mode='max', factor=0.5, patience=2, verbose=True\n",")\n","\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","best_val_acc = 0.0\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_loss = 0.0\n","    train_correct = 0\n","    for idx, batch in tqdm(enumerate(train_loader), total = len(train_loader)):\n","        images = batch[\"image\"].to(device)\n","        texts = batch[\"text\"].to(device)\n","        labels = batch[\"label\"].to(device)\n","        optimizer.zero_grad()\n","        outputs, loss = model(texts, images, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item() * images.size(0)\n","        train_correct += torch.sum(torch.argmax(outputs, dim=1) == labels)\n","\n","    train_loss /= len(train_loader.dataset)\n","    train_accuracy = train_correct.float() / len(train_loader.dataset)\n","\n","    model.eval()\n","\n","    val_loss = 0.0\n","    val_correct = 0\n","\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            images = batch[\"image\"].to(device)\n","            texts = batch[\"text\"].to(device)\n","            labels = batch[\"label\"].to(device)\n","            outputs, loss = model(texts, images, labels)\n","            val_loss += loss.item() * images.size(0)\n","            val_correct += torch.sum(torch.argmax(outputs, dim=1) == labels)\n","\n","    val_loss /= len(test_loader.dataset)\n","    val_accuracy = val_correct.float() / len(test_loader.dataset)\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n","  "]},{"cell_type":"markdown","source":["## Experiment 2: Only text\n","\n","hypothesis: Resnet is overfitting the model, let's use only text model\n","\n","- Lr = 1e-5 dropout = 0.2 FC_length = 50, batch_size = 64, +normalization_layer Train Loss: 0.5001, Train Accuracy: 0.8171, Val Loss: 0.7392, Val Accuracy: 0.5240\n","- Lr = 1e-5 dropout = 0.2 FC_length = 50, batch_size = 64, -last FCL, Train Loss: 0.5098, Train Accuracy: 0.7995, Val Loss: 0.7550, Val Accuracy: 0.5340\n","- Lr = 1e-5 dropout = 0.2 FC_length = 50, batch_size = 64, -last FCL, +balanced, Train Loss: 0.4983, Train Accuracy: 0.8031, Val Loss: 0.7113, Val Accuracy: 0.5800"],"metadata":{"id":"aDWA0i_IXdo0"}},{"cell_type":"code","source":["from transformers import BertTokenizer\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n","text_transform = tokenizer"],"metadata":{"id":"9i_dnsG_aeFm"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class HatefulMemesDataset(torch.utils.data.Dataset):\n","    \"\"\"Uses jsonl data to preprocess and serve \n","    dictionary of multimodal tensors for model input.\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        data_path,\n","        img_dir,\n","        image_transform,\n","        text_transform,\n","        balance=False,\n","        dev_limit=None,\n","        random_state=0,\n","    ):\n","\n","        self.samples_frame = pd.read_json(\n","            data_path, lines=True\n","        )\n","        self.dev_limit = dev_limit\n","        if balance:\n","            neg = self.samples_frame[\n","                self.samples_frame.label.eq(0)\n","            ]\n","            pos = self.samples_frame[\n","                self.samples_frame.label.eq(1)\n","            ]\n","            self.samples_frame = pd.concat(\n","                [\n","                    neg.sample(\n","                        pos.shape[0], \n","                        random_state=random_state\n","                    ), \n","                    pos\n","                ]\n","            )\n","        if self.dev_limit:\n","            if self.samples_frame.shape[0] > self.dev_limit:\n","                self.samples_frame = self.samples_frame.sample(\n","                    dev_limit, random_state=random_state\n","                )\n","        self.samples_frame = self.samples_frame.reset_index(\n","            drop=True\n","        )\n","        self.samples_frame.img = self.samples_frame.apply(\n","            lambda row: (img_dir / row.img), axis=1\n","        )\n","\n","        # https://github.com/drivendataorg/pandas-path\n","        for path in self.samples_frame.img:\n","            if not path.exists():\n","                raise FileNotFoundError(f'{path} doesnt seem to exist')\n","            if not path.is_file():\n","                raise TypeError(f'{path} doesnt seem to be a file')\n","            \n","        self.image_transform = image_transform\n","        self.text_transform = text_transform\n","\n","    def __len__(self):\n","        \"\"\"This method is called when you do len(instance) \n","        for an instance of this class.\n","        \"\"\"\n","        return len(self.samples_frame)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"This method is called when you do instance[key] \n","        for an instance of this class.\n","        \"\"\"\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        img_id = self.samples_frame.loc[idx, \"id\"]\n","\n","        text = torch.Tensor(\n","            self.text_transform(\n","                self.samples_frame.loc[idx, \"text\"],\n","                max_length=20,\n","                padding='max_length',\n","                truncation=True, \n","                return_tensors=\"pt\"\n","            ).input_ids\n","        ).squeeze()\n","\n","        if \"label\" in self.samples_frame.columns:\n","            label = torch.Tensor(\n","                [self.samples_frame.loc[idx, \"label\"]]\n","            ).long().squeeze()\n","            sample = {\n","                \"id\": img_id,\n","                \"text\": text, \n","                \"label\": label\n","            }\n","        else:\n","            sample = {\n","                \"id\": img_id, \n","                \"image\": image, \n","                \"text\": text\n","            }\n","\n","        return sample"],"metadata":{"id":"RRlp0L-ZXiy9"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class LanguageAndVisionConcat(torch.nn.Module):\n","    def __init__(\n","        self,\n","        num_classes,\n","        loss_fn,\n","        language_module,\n","        vision_module,\n","        language_feature_dim,\n","        vision_feature_dim,\n","        fusion_output_size,\n","        dropout_p,\n","        \n","    ):\n","        super(LanguageAndVisionConcat, self).__init__()\n","        self.language_module = language_module\n","        self.fusion = torch.nn.Linear(\n","            in_features=(language_feature_dim), \n","            out_features=num_classes\n","        )\n","        #self.norm = torch.nn.BatchNorm1d(fusion_output_size)\n","        #self.fc = torch.nn.Linear(\n","        #    in_features=fusion_output_size, \n","        #    out_features=num_classes\n","        #)\n","        self.loss_fn = loss_fn\n","        self.dropout = torch.nn.Dropout(dropout_p)\n","        \n","    def forward(self, text, image, label=None):\n","\n","        text_features = torch.nn.functional.relu(\n","            self.language_module(text).last_hidden_state.mean(dim=1)\n","        )\n","\n","        fused = self.dropout(\n","            torch.nn.functional.relu(\n","            self.fusion(text_features)\n","            )\n","        )\n","        #normalized = self.norm(fused)\n","        #logits = self.fc(text_features)\n","        pred = torch.nn.functional.softmax(fused)\n","        loss = (\n","            self.loss_fn(pred, label) \n","            if label is not None else label\n","        )\n","        return (pred, loss)"],"metadata":{"id":"31jxdn_hY089"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["params = {\n","    \"lr\": 1e-5, \n","    \"batch_size\": 64,\n","    \"num_epochs\": 10,\n","    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n","    \"balance\": True,\n","    \"dev_limit\": None,\n","    \"random_state\": 0,\n","    \"dropout\": 0.2,\n","    \"fusion_output_size\": 50}\n","\n","\n","balance = params[\"balance\"]\n","dev_limit = params[\"dev_limit\"]\n","random_state = params[\"random_state\"]\n","batch_size = params[\"batch_size\"]\n","num_epochs = params[\"num_epochs\"]\n","lr = params[\"lr\"]\n","device = params[\"device\"]\n","dropout = params[\"dropout\"]\n","fusion_output_size = params[\"fusion_output_size\"]\n","language_feature_dim = 768\n","\n","\n","training_data = HatefulMemesDataset(data_path=train_path,\n","    img_dir=Path('.'),\n","    text_transform=text_transform,\n","    image_transform=None,\n","    balance= balance,\n","    dev_limit= dev_limit,\n","    random_state= random_state)\n","\n","validation_data = HatefulMemesDataset(data_path=dev_path,\n","    img_dir=Path('.'),\n","    text_transform=text_transform,\n","    image_transform=None,\n","    balance= balance,\n","    dev_limit= dev_limit,\n","    random_state= random_state)\n","\n","train_loader = DataLoader(training_data,\n","                          batch_size = batch_size,\n","                          shuffle= True,\n","                          num_workers = 2)\n","\n","test_loader = DataLoader(validation_data,\n","                          batch_size = batch_size,\n","                          shuffle=True,\n","                          num_workers = 2)\n","\n","text_model = BertModel.from_pretrained('bert-base-uncased')\n","vision_model = models.resnet50(pretrained=True)\n","\n","model = LanguageAndVisionConcat(\n","    num_classes = 2,\n","    loss_fn = torch.nn.CrossEntropyLoss(),\n","    language_module = text_model,\n","    vision_module = None,\n","    language_feature_dim = language_feature_dim,\n","    vision_feature_dim = 1000,\n","    fusion_output_size = fusion_output_size,\n","    dropout_p = 0.1\n",").to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","    optimizer, mode='max', factor=0.5, patience=2, verbose=True\n",")\n","\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","best_val_acc = 0.0\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_loss = 0.0\n","    train_correct = 0\n","    for idx, batch in tqdm(enumerate(train_loader), total = len(train_loader)):\n","        texts = batch[\"text\"].to(device)\n","        labels = batch[\"label\"].to(device)\n","        optimizer.zero_grad()\n","        outputs, loss = model(texts, None, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item() * texts.size(0)\n","        train_correct += torch.sum(torch.argmax(outputs, dim=1) == labels)\n","\n","    train_loss /= len(train_loader.dataset)\n","    train_accuracy = train_correct.float() / len(train_loader.dataset)\n","\n","    model.eval()\n","\n","    val_loss = 0.0\n","    val_correct = 0\n","\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            texts = batch[\"text\"].to(device)\n","            labels = batch[\"label\"].to(device)\n","            outputs, loss = model(texts, None, labels)\n","            val_loss += loss.item() * texts.size(0)\n","            val_correct += torch.sum(torch.argmax(outputs, dim=1) == labels)\n","\n","    val_loss /= len(test_loader.dataset)\n","    val_accuracy = val_correct.float() / len(test_loader.dataset)\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n","  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"FcVXcgS8Y8rH","outputId":"4a9a2fec-8997-434c-9cf8-ac52e1f98cb8","executionInfo":{"status":"ok","timestamp":1682720223702,"user_tz":300,"elapsed":238647,"user":{"displayName":"Michael rivera","userId":"11271803176980018053"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias']\n","- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","  0%|          | 0/96 [00:00<?, ?it/s]<ipython-input-19-e76cbefbed53>:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  pred = torch.nn.functional.softmax(fused)\n","100%|██████████| 96/96 [00:21<00:00,  4.47it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Train Loss: 0.6683, Train Accuracy: 0.5841, Val Loss: 0.6786, Val Accuracy: 0.5840\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:21<00:00,  4.38it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/10, Train Loss: 0.6160, Train Accuracy: 0.6690, Val Loss: 0.6881, Val Accuracy: 0.5740\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:23<00:00,  4.11it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/10, Train Loss: 0.5885, Train Accuracy: 0.6982, Val Loss: 0.6919, Val Accuracy: 0.5860\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:23<00:00,  4.10it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/10, Train Loss: 0.5660, Train Accuracy: 0.7252, Val Loss: 0.6966, Val Accuracy: 0.5780\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:22<00:00,  4.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/10, Train Loss: 0.5470, Train Accuracy: 0.7497, Val Loss: 0.7096, Val Accuracy: 0.5780\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:22<00:00,  4.31it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/10, Train Loss: 0.5382, Train Accuracy: 0.7559, Val Loss: 0.7067, Val Accuracy: 0.5700\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:22<00:00,  4.23it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/10, Train Loss: 0.5227, Train Accuracy: 0.7744, Val Loss: 0.7062, Val Accuracy: 0.5860\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:22<00:00,  4.28it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8/10, Train Loss: 0.5102, Train Accuracy: 0.7870, Val Loss: 0.7220, Val Accuracy: 0.5720\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:22<00:00,  4.26it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9/10, Train Loss: 0.5058, Train Accuracy: 0.7956, Val Loss: 0.7224, Val Accuracy: 0.5660\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:22<00:00,  4.30it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Train Loss: 0.4981, Train Accuracy: 0.7990, Val Loss: 0.7284, Val Accuracy: 0.5700\n"]}]},{"cell_type":"markdown","source":["# Experiment 3:\n","\n","- RoBERTa instead of BERT\n","\n","-  \"lr\": 3e-5, batch_size = 64 Train Loss: 0.6507, Train Accuracy: 0.6279, Val Loss: 0.6948, Val Accuracy: 0.5580"],"metadata":{"id":"cHpgNEFHQpYR"}},{"cell_type":"code","source":["tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","text_transform = tokenizer"],"metadata":{"id":"KqrM9-2_SR52"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class HatefulMemesDataset(torch.utils.data.Dataset):\n","    \"\"\"Uses jsonl data to preprocess and serve \n","    dictionary of multimodal tensors for model input.\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        data_path,\n","        img_dir,\n","        image_transform,\n","        text_transform,\n","        balance=False,\n","        dev_limit=None,\n","        random_state=0,\n","    ):\n","\n","        self.samples_frame = pd.read_json(\n","            data_path, lines=True\n","        )\n","        self.dev_limit = dev_limit\n","        if balance:\n","            neg = self.samples_frame[\n","                self.samples_frame.label.eq(0)\n","            ]\n","            pos = self.samples_frame[\n","                self.samples_frame.label.eq(1)\n","            ]\n","            self.samples_frame = pd.concat(\n","                [\n","                    neg.sample(\n","                        pos.shape[0], \n","                        random_state=random_state\n","                    ), \n","                    pos\n","                ]\n","            )\n","        if self.dev_limit:\n","            if self.samples_frame.shape[0] > self.dev_limit:\n","                self.samples_frame = self.samples_frame.sample(\n","                    dev_limit, random_state=random_state\n","                )\n","        self.samples_frame = self.samples_frame.reset_index(\n","            drop=True\n","        )\n","        self.samples_frame.img = self.samples_frame.apply(\n","            lambda row: (img_dir / row.img), axis=1\n","        )\n","\n","        # https://github.com/drivendataorg/pandas-path\n","        for path in self.samples_frame.img:\n","            if not path.exists():\n","                raise FileNotFoundError(f'{path} doesnt seem to exist')\n","            if not path.is_file():\n","                raise TypeError(f'{path} doesnt seem to be a file')\n","            \n","        self.image_transform = image_transform\n","        self.text_transform = text_transform\n","\n","    def __len__(self):\n","        \"\"\"This method is called when you do len(instance) \n","        for an instance of this class.\n","        \"\"\"\n","        return len(self.samples_frame)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"This method is called when you do instance[key] \n","        for an instance of this class.\n","        \"\"\"\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        img_id = self.samples_frame.loc[idx, \"id\"]\n","\n","        text = torch.Tensor(\n","            self.text_transform(\n","                self.samples_frame.loc[idx, \"text\"],\n","                max_length=20,\n","                padding='max_length',\n","                truncation=True, \n","                return_tensors=\"pt\"\n","            ).input_ids\n","        ).squeeze()\n","\n","        if \"label\" in self.samples_frame.columns:\n","            label = torch.Tensor(\n","                [self.samples_frame.loc[idx, \"label\"]]\n","            ).long().squeeze()\n","            sample = {\n","                \"id\": img_id,\n","                \"text\": text, \n","                \"label\": label\n","            }\n","        else:\n","            sample = {\n","                \"id\": img_id, \n","                \"image\": image, \n","                \"text\": text\n","            }\n","\n","        return sample"],"metadata":{"id":"FdE7bifzSR6V"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class LanguageAndVisionConcat(torch.nn.Module):\n","    def __init__(\n","        self,\n","        num_classes,\n","        loss_fn,\n","        language_module,\n","        vision_module,\n","        language_feature_dim,\n","        vision_feature_dim,\n","        fusion_output_size,\n","        dropout_p,\n","        \n","    ):\n","        super(LanguageAndVisionConcat, self).__init__()\n","        self.language_module = language_module\n","        self.fusion = torch.nn.Linear(\n","            in_features=(language_feature_dim), \n","            out_features=num_classes\n","        )\n","        #self.norm = torch.nn.BatchNorm1d(fusion_output_size)\n","        #self.fc = torch.nn.Linear(\n","        #    in_features=fusion_output_size, \n","        #    out_features=num_classes\n","        #)\n","        self.loss_fn = loss_fn\n","        self.dropout = torch.nn.Dropout(dropout_p)\n","        \n","    def forward(self, text, image, label=None):\n","\n","        text_features = torch.nn.functional.relu(\n","            self.language_module(text).last_hidden_state.mean(dim=1)\n","        )\n","\n","        fused = self.dropout(\n","            torch.nn.functional.relu(\n","            self.fusion(text_features)\n","            )\n","        )\n","        #normalized = self.norm(fused)\n","        #logits = self.fc(text_features)\n","        pred = torch.nn.functional.softmax(fused)\n","        loss = (\n","            self.loss_fn(pred, label) \n","            if label is not None else label\n","        )\n","        return (pred, loss)"],"metadata":{"id":"jcEEIRpzSR6X"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["params = {\n","    \"lr\": 1e-5, \n","    \"batch_size\": 64,\n","    \"num_epochs\": 10,\n","    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n","    \"balance\": True,\n","    \"dev_limit\": None,\n","    \"random_state\": 0,\n","    \"dropout\": 0.2,\n","    \"fusion_output_size\": 50}\n","\n","\n","balance = params[\"balance\"]\n","dev_limit = params[\"dev_limit\"]\n","random_state = params[\"random_state\"]\n","batch_size = params[\"batch_size\"]\n","num_epochs = params[\"num_epochs\"]\n","lr = params[\"lr\"]\n","device = params[\"device\"]\n","dropout = params[\"dropout\"]\n","fusion_output_size = params[\"fusion_output_size\"]\n","language_feature_dim = 768\n","\n","\n","training_data = HatefulMemesDataset(data_path=train_path,\n","    img_dir=Path('.'),\n","    text_transform=text_transform,\n","    image_transform=None,\n","    balance= balance,\n","    dev_limit= dev_limit,\n","    random_state= random_state)\n","\n","validation_data = HatefulMemesDataset(data_path=dev_path,\n","    img_dir=Path('.'),\n","    text_transform=text_transform,\n","    image_transform=None,\n","    balance= balance,\n","    dev_limit= dev_limit,\n","    random_state= random_state)\n","\n","train_loader = DataLoader(training_data,\n","                          batch_size = batch_size,\n","                          shuffle= True,\n","                          num_workers = 2)\n","\n","test_loader = DataLoader(validation_data,\n","                          batch_size = batch_size,\n","                          shuffle=True,\n","                          num_workers = 2)\n","\n","text_model = RobertaModel.from_pretrained('roberta-base')\n","vision_model = models.resnet50(pretrained=True)\n","\n","model = LanguageAndVisionConcat(\n","    num_classes = 2,\n","    loss_fn = torch.nn.CrossEntropyLoss(),\n","    language_module = text_model,\n","    vision_module = None,\n","    language_feature_dim = language_feature_dim,\n","    vision_feature_dim = 1000,\n","    fusion_output_size = fusion_output_size,\n","    dropout_p = dropout\n",").to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","    optimizer, mode='max', factor=0.5, patience=2, verbose=True\n",")\n","\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","best_val_acc = 0.0\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_loss = 0.0\n","    train_correct = 0\n","    for idx, batch in tqdm(enumerate(train_loader), total = len(train_loader)):\n","        texts = batch[\"text\"].to(device)\n","        labels = batch[\"label\"].to(device)\n","        optimizer.zero_grad()\n","        outputs, loss = model(texts, None, labels)\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item() * texts.size(0)\n","        train_correct += torch.sum(torch.argmax(outputs, dim=1) == labels)\n","\n","    train_loss /= len(train_loader.dataset)\n","    train_accuracy = train_correct.float() / len(train_loader.dataset)\n","\n","    model.eval()\n","\n","    val_loss = 0.0\n","    val_correct = 0\n","\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            texts = batch[\"text\"].to(device)\n","            labels = batch[\"label\"].to(device)\n","            outputs, loss = model(texts, None, labels)\n","            val_loss += loss.item() * texts.size(0)\n","            val_correct += torch.sum(torch.argmax(outputs, dim=1) == labels)\n","\n","    val_loss /= len(test_loader.dataset)\n","    val_accuracy = val_correct.float() / len(test_loader.dataset)\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n","  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"6905fc18-30f2-48e2-f8ff-a7302608bc5c","id":"p1q1MGjuSR6Y","executionInfo":{"status":"ok","timestamp":1682720455319,"user_tz":300,"elapsed":231687,"user":{"displayName":"Michael rivera","userId":"11271803176980018053"}}},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.layer_norm.bias', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.decoder.weight', 'lm_head.layer_norm.weight', 'lm_head.dense.bias']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","  0%|          | 0/96 [00:00<?, ?it/s]<ipython-input-23-e76cbefbed53>:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  pred = torch.nn.functional.softmax(fused)\n","100%|██████████| 96/96 [00:21<00:00,  4.41it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Train Loss: 0.6931, Train Accuracy: 0.5000, Val Loss: 0.6931, Val Accuracy: 0.5000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:21<00:00,  4.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/10, Train Loss: 0.6931, Train Accuracy: 0.5000, Val Loss: 0.6931, Val Accuracy: 0.5000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:21<00:00,  4.43it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/10, Train Loss: 0.6931, Train Accuracy: 0.5000, Val Loss: 0.6931, Val Accuracy: 0.5000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:21<00:00,  4.48it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/10, Train Loss: 0.6931, Train Accuracy: 0.5000, Val Loss: 0.6931, Val Accuracy: 0.5000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:21<00:00,  4.44it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/10, Train Loss: 0.6931, Train Accuracy: 0.5000, Val Loss: 0.6931, Val Accuracy: 0.5000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:21<00:00,  4.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/10, Train Loss: 0.6931, Train Accuracy: 0.5000, Val Loss: 0.6931, Val Accuracy: 0.5000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:21<00:00,  4.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/10, Train Loss: 0.6931, Train Accuracy: 0.5000, Val Loss: 0.6931, Val Accuracy: 0.5000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:21<00:00,  4.40it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8/10, Train Loss: 0.6931, Train Accuracy: 0.4998, Val Loss: 0.6931, Val Accuracy: 0.5000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:21<00:00,  4.46it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9/10, Train Loss: 0.6931, Train Accuracy: 0.5000, Val Loss: 0.6931, Val Accuracy: 0.5000\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:21<00:00,  4.42it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Train Loss: 0.6931, Train Accuracy: 0.5000, Val Loss: 0.6931, Val Accuracy: 0.5000\n"]}]},{"cell_type":"markdown","source":["## Experiment 4: \n","\n","Only RoBERTa with L2 Regularization\n","\n","- Train Loss: 53.9597, Train Accuracy: 0.7385, Val Loss: 0.7145, Val Accuracy: 0.5740\n","- Train Accuracy: 0.5534, Val Loss: 0.6752, Val Accuracy: 0.5960"],"metadata":{"id":"ah4RzmusIkES"}},{"cell_type":"code","source":["tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n","text_transform = tokenizer"],"metadata":{"executionInfo":{"status":"ok","timestamp":1682801161311,"user_tz":300,"elapsed":1259,"user":{"displayName":"Michael rivera","userId":"11271803176980018053"}},"id":"OyQge0UuMI8p","colab":{"base_uri":"https://localhost:8080/","height":113,"referenced_widgets":["28c85acd45ef483494a80a3b48591fa3","e4cf363e498a4c249b9d9ffc6fce58b5","3ac068f1cc154c3fb676c6c8f51dd906","a1b68284f6b34a46b3808e6694884d19","48f017766a14467bb938504e94de4b6c","8ad38b0c7c1046b596771cfdd4c07172","5d2311c94c994dccb7496629a1b1ca53","cfc8a6a7ab3c4fae9af3dde51b6b586d","cb8d34b95b4b477287cf1b625079f70f","d60db0da02c949839dd5b3d633eeba23","46ddbf3d87a746b89843e74c443b0aba","aba597ece797419ca111f6a0cb4834a2","38f8c4f2485845ce996b09932c824aa7","d7055f415a1146b0931c9480b769f540","1d8bb48c048c400c9a2203d7d87295e7","1a3efd38952a4c13afdbe6ecacf5b340","8fe41b72eb894993a98069c803b0c6f1","6795332271da4fd2885079b15dd7fd3c","26e00d356a164f85a5bf188d5acfd640","7196461d2fe741008de299a17ba84a4e","f49007edf72145ea9da29b4b6df99124","7be512ac48ba48d3880559bb9e07e906","a0f5c474ef3c4ef3beb04ed821026076","d712329025e94029bcc0f472bfc3d881","3efac100e02c4a129c00287f94cc3cdc","170312ec76cd4f3291743276c65de800","0d6742694b444cbc8fd86f33771298af","70ad8983d0ef48238c465c666455c4c0","bc21ed603f94406e9d916d9260f2bc22","4bea91231e7849c8a2cf3913b94691f1","e2a9f2c887c749d19b873c5700a16b71","c7f48b6088164562b2238b70a7c1e0e0","75874fa7bf034ad29714653370735bef"]},"outputId":"e2fcba61-5506-4063-f8bf-aafc2fc24b54"},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28c85acd45ef483494a80a3b48591fa3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aba597ece797419ca111f6a0cb4834a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["Downloading (…)lve/main/config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]"],"application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a0f5c474ef3c4ef3beb04ed821026076"}},"metadata":{}}]},{"cell_type":"code","source":["class HatefulMemesDataset(torch.utils.data.Dataset):\n","    \"\"\"Uses jsonl data to preprocess and serve \n","    dictionary of multimodal tensors for model input.\n","    \"\"\"\n","\n","    def __init__(\n","        self,\n","        data_path,\n","        img_dir,\n","        image_transform,\n","        text_transform,\n","        balance=False,\n","        dev_limit=None,\n","        random_state=0,\n","    ):\n","\n","        self.samples_frame = pd.read_json(\n","            data_path, lines=True\n","        )\n","        self.dev_limit = dev_limit\n","        if balance:\n","            neg = self.samples_frame[\n","                self.samples_frame.label.eq(0)\n","            ]\n","            pos = self.samples_frame[\n","                self.samples_frame.label.eq(1)\n","            ]\n","            self.samples_frame = pd.concat(\n","                [\n","                    neg.sample(\n","                        pos.shape[0], \n","                        random_state=random_state\n","                    ), \n","                    pos\n","                ]\n","            )\n","        if self.dev_limit:\n","            if self.samples_frame.shape[0] > self.dev_limit:\n","                self.samples_frame = self.samples_frame.sample(\n","                    dev_limit, random_state=random_state\n","                )\n","        self.samples_frame = self.samples_frame.reset_index(\n","            drop=True\n","        )\n","        self.samples_frame.img = self.samples_frame.apply(\n","            lambda row: (img_dir / row.img), axis=1\n","        )\n","\n","        # https://github.com/drivendataorg/pandas-path\n","        for path in self.samples_frame.img:\n","            if not path.exists():\n","                raise FileNotFoundError(f'{path} doesnt seem to exist')\n","            if not path.is_file():\n","                raise TypeError(f'{path} doesnt seem to be a file')\n","            \n","        self.image_transform = image_transform\n","        self.text_transform = text_transform\n","\n","    def __len__(self):\n","        \"\"\"This method is called when you do len(instance) \n","        for an instance of this class.\n","        \"\"\"\n","        return len(self.samples_frame)\n","\n","    def __getitem__(self, idx):\n","        \"\"\"This method is called when you do instance[key] \n","        for an instance of this class.\n","        \"\"\"\n","        if torch.is_tensor(idx):\n","            idx = idx.tolist()\n","\n","        img_id = self.samples_frame.loc[idx, \"id\"]\n","\n","        text = torch.Tensor(\n","            self.text_transform(\n","                self.samples_frame.loc[idx, \"text\"],\n","                max_length=20,\n","                padding='max_length',\n","                truncation=True, \n","                return_tensors=\"pt\"\n","            ).input_ids\n","        ).squeeze()\n","\n","        if \"label\" in self.samples_frame.columns:\n","            label = torch.Tensor(\n","                [self.samples_frame.loc[idx, \"label\"]]\n","            ).long().squeeze()\n","            sample = {\n","                \"id\": img_id,\n","                \"text\": text, \n","                \"label\": label\n","            }\n","        else:\n","            sample = {\n","                \"id\": img_id, \n","                \"image\": image, \n","                \"text\": text\n","            }\n","\n","        return sample"],"metadata":{"id":"GHP8AfLkMI9C","executionInfo":{"status":"ok","timestamp":1682801166906,"user_tz":300,"elapsed":257,"user":{"displayName":"Michael rivera","userId":"11271803176980018053"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["class LanguageAndVisionConcat(torch.nn.Module):\n","    def __init__(\n","        self,\n","        num_classes,\n","        loss_fn,\n","        language_module,\n","        vision_module,\n","        language_feature_dim,\n","        vision_feature_dim,\n","        fusion_output_size,\n","        dropout_p,\n","        \n","    ):\n","        super(LanguageAndVisionConcat, self).__init__()\n","        self.language_module = language_module\n","        self.fusion = torch.nn.Linear(\n","            in_features=(language_feature_dim), \n","            out_features=num_classes\n","        )\n","        #self.norm = torch.nn.BatchNorm1d(fusion_output_size)\n","        #self.fc = torch.nn.Linear(\n","        #    in_features=fusion_output_size, \n","        #    out_features=num_classes\n","        #)\n","        self.loss_fn = loss_fn\n","        self.dropout = torch.nn.Dropout(dropout_p)\n","        \n","    def forward(self, text, image, label=None):\n","\n","        text_features = torch.nn.functional.relu(\n","            self.language_module(text).last_hidden_state.mean(dim=1)\n","        )\n","\n","        fused = self.dropout(\n","            torch.nn.functional.relu(\n","            self.fusion(text_features)\n","            )\n","        )\n","        #normalized = self.norm(fused)\n","        #logits = self.fc(text_features)\n","        pred = torch.nn.functional.softmax(fused)\n","        loss = (\n","            self.loss_fn(pred, label) \n","            if label is not None else label\n","        )\n","        return (pred, loss)"],"metadata":{"id":"hpK5i6ksMI9D","executionInfo":{"status":"ok","timestamp":1682801171765,"user_tz":300,"elapsed":222,"user":{"displayName":"Michael rivera","userId":"11271803176980018053"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["params = {\n","    \"lr\": 1e-5, \n","    \"batch_size\": 64,\n","    \"num_epochs\": 10,\n","    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n","    \"balance\": True,\n","    \"dev_limit\": None,\n","    \"random_state\": 0,\n","    \"dropout\": 0.2,\n","    \"fusion_output_size\": 50}\n","\n","\n","balance = params[\"balance\"]\n","dev_limit = params[\"dev_limit\"]\n","random_state = params[\"random_state\"]\n","batch_size = params[\"batch_size\"]\n","num_epochs = params[\"num_epochs\"]\n","lr = params[\"lr\"]\n","device = params[\"device\"]\n","dropout = params[\"dropout\"]\n","fusion_output_size = params[\"fusion_output_size\"]\n","language_feature_dim = 768\n","l2_lambda = 0.00001\n","\n","\n","training_data = HatefulMemesDataset(data_path=train_path,\n","    img_dir=Path('.'),\n","    text_transform=text_transform,\n","    image_transform=None,\n","    balance= balance,\n","    dev_limit= dev_limit,\n","    random_state= random_state)\n","\n","validation_data = HatefulMemesDataset(data_path=dev_path,\n","    img_dir=Path('.'),\n","    text_transform=text_transform,\n","    image_transform=None,\n","    balance= balance,\n","    dev_limit= dev_limit,\n","    random_state= random_state)\n","\n","train_loader = DataLoader(training_data,\n","                          batch_size = batch_size,\n","                          shuffle= True,\n","                          num_workers = 2)\n","\n","test_loader = DataLoader(validation_data,\n","                          batch_size = batch_size,\n","                          shuffle=True,\n","                          num_workers = 2)\n","\n","text_model = RobertaModel.from_pretrained('roberta-base')\n","vision_model = models.resnet50(pretrained=True)\n","\n","model = LanguageAndVisionConcat(\n","    num_classes = 2,\n","    loss_fn = torch.nn.CrossEntropyLoss(),\n","    language_module = text_model,\n","    vision_module = None,\n","    language_feature_dim = language_feature_dim,\n","    vision_feature_dim = 1000,\n","    fusion_output_size = fusion_output_size,\n","    dropout_p = dropout\n",").to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=lr)\n","scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n","    optimizer, mode='max', factor=0.5, patience=2, verbose=True\n",")\n","\n","loss_fn = torch.nn.CrossEntropyLoss()\n","\n","best_val_acc = 0.0\n","\n","for epoch in range(num_epochs):\n","    model.train()\n","    train_loss = 0.0\n","    train_correct = 0\n","    for idx, batch in tqdm(enumerate(train_loader), total = len(train_loader)):\n","        texts = batch[\"text\"].to(device)\n","        labels = batch[\"label\"].to(device)\n","        optimizer.zero_grad()\n","        outputs, loss = model(texts, None, labels)\n","        l2_reg = 0\n","        for param in model.parameters():\n","            l2_reg += torch.norm(param)\n","        loss += l2_lambda * l2_reg\n","        loss.backward()\n","        optimizer.step()\n","        train_loss += loss.item() * texts.size(0)\n","        train_correct += torch.sum(torch.argmax(outputs, dim=1) == labels)\n","\n","    train_loss /= len(train_loader.dataset)\n","    train_accuracy = train_correct.float() / len(train_loader.dataset)\n","\n","    model.eval()\n","\n","    val_loss = 0.0\n","    val_correct = 0\n","\n","    with torch.no_grad():\n","        for batch in test_loader:\n","            texts = batch[\"text\"].to(device)\n","            labels = batch[\"label\"].to(device)\n","            outputs, loss = model(texts, None, labels)\n","            val_loss += loss.item() * texts.size(0)\n","            val_correct += torch.sum(torch.argmax(outputs, dim=1) == labels)\n","\n","    val_loss /= len(test_loader.dataset)\n","    val_accuracy = val_correct.float() / len(test_loader.dataset)\n","\n","    print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.4f}, Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n","  "],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"outputId":"347f3bec-9628-4999-c4c8-86f7c0a7476e","executionInfo":{"status":"ok","timestamp":1682804512249,"user_tz":300,"elapsed":277413,"user":{"displayName":"Michael rivera","userId":"11271803176980018053"}},"id":"bFKhsP9hMI9E"},"execution_count":18,"outputs":[{"output_type":"stream","name":"stderr","text":["Some weights of the model checkpoint at roberta-base were not used when initializing RobertaModel: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight']\n","- This IS expected if you are initializing RobertaModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n","- This IS NOT expected if you are initializing RobertaModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n","  warnings.warn(\n","/usr/local/lib/python3.10/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n","  warnings.warn(msg)\n","  0%|          | 0/96 [00:00<?, ?it/s]<ipython-input-8-e76cbefbed53>:41: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n","  pred = torch.nn.functional.softmax(fused)\n","100%|██████████| 96/96 [00:26<00:00,  3.64it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 1/10, Train Loss: 0.7318, Train Accuracy: 0.5652, Val Loss: 0.7093, Val Accuracy: 0.5100\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:26<00:00,  3.61it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 2/10, Train Loss: 0.6950, Train Accuracy: 0.6272, Val Loss: 0.6881, Val Accuracy: 0.5780\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:25<00:00,  3.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 3/10, Train Loss: 0.6751, Train Accuracy: 0.6533, Val Loss: 0.6888, Val Accuracy: 0.5740\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:26<00:00,  3.67it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 4/10, Train Loss: 0.6611, Train Accuracy: 0.6702, Val Loss: 0.7019, Val Accuracy: 0.5620\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:26<00:00,  3.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 5/10, Train Loss: 0.6480, Train Accuracy: 0.6844, Val Loss: 0.6935, Val Accuracy: 0.5700\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:26<00:00,  3.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 6/10, Train Loss: 0.6399, Train Accuracy: 0.6949, Val Loss: 0.6754, Val Accuracy: 0.5960\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:25<00:00,  3.69it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 7/10, Train Loss: 0.6349, Train Accuracy: 0.6987, Val Loss: 0.6926, Val Accuracy: 0.5720\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:25<00:00,  3.70it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 8/10, Train Loss: 0.6271, Train Accuracy: 0.7131, Val Loss: 0.7161, Val Accuracy: 0.5680\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:26<00:00,  3.68it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 9/10, Train Loss: 0.6173, Train Accuracy: 0.7125, Val Loss: 0.7009, Val Accuracy: 0.5700\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 96/96 [00:26<00:00,  3.65it/s]\n"]},{"output_type":"stream","name":"stdout","text":["Epoch 10/10, Train Loss: 0.6057, Train Accuracy: 0.7370, Val Loss: 0.7003, Val Accuracy: 0.5740\n"]}]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPi0LdhlGWTjhsWG+75TaWw"},"gpuClass":"standard","kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b1f8b1b206e64aa0ac76f981fb054d7b":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_538f70f847ba4693b9d1955b9cabae95","IPY_MODEL_d8f72d85ddbd4f1fb778d69b7feff2de","IPY_MODEL_ef252daef8c8403c87013e7e9471a2dc"],"layout":"IPY_MODEL_ac37a2ff350042bfbb8237e50b398366"}},"538f70f847ba4693b9d1955b9cabae95":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_60bca1b8b3154f92a083602fdc892d9d","placeholder":"​","style":"IPY_MODEL_c89061a97b4e420890730fc334ff1db4","value":"Downloading (…)solve/main/vocab.txt: 100%"}},"d8f72d85ddbd4f1fb778d69b7feff2de":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f09607aa9b6e4b629274ededa07cac9d","max":231508,"min":0,"orientation":"horizontal","style":"IPY_MODEL_fc0b55a4565d4f5fbacfebd69be8ea95","value":231508}},"ef252daef8c8403c87013e7e9471a2dc":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8e4f2cbd71874a168081b66f181a9547","placeholder":"​","style":"IPY_MODEL_57eab05385e4479384979dc772514e7a","value":" 232k/232k [00:00&lt;00:00, 3.18MB/s]"}},"ac37a2ff350042bfbb8237e50b398366":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"60bca1b8b3154f92a083602fdc892d9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"c89061a97b4e420890730fc334ff1db4":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"f09607aa9b6e4b629274ededa07cac9d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"fc0b55a4565d4f5fbacfebd69be8ea95":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"8e4f2cbd71874a168081b66f181a9547":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"57eab05385e4479384979dc772514e7a":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"b823574261e74f4fbcee9ffa99bca7e3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_295bbbe656544415962050c71dffc7f2","IPY_MODEL_a17beec42cd54e21b2ea78db7dbde672","IPY_MODEL_011fa4e606ae4c4bb54edac674ce06ac"],"layout":"IPY_MODEL_bce83093ebff4ea09d4fa059aa4c0550"}},"295bbbe656544415962050c71dffc7f2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b44f17bbfcb94e5da8d24ca845c5c9b4","placeholder":"​","style":"IPY_MODEL_eee11cb6a4664b94b8097a46a2a79dbe","value":"Downloading (…)okenizer_config.json: 100%"}},"a17beec42cd54e21b2ea78db7dbde672":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_7b3c866abb5847579852ba1bac610c20","max":28,"min":0,"orientation":"horizontal","style":"IPY_MODEL_2d7893dc076440d6984eca4565e2f6a8","value":28}},"011fa4e606ae4c4bb54edac674ce06ac":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_63820311ddba46058a21e38b3ec2411f","placeholder":"​","style":"IPY_MODEL_ef8368aee1934a319d9bec718697a2be","value":" 28.0/28.0 [00:00&lt;00:00, 467B/s]"}},"bce83093ebff4ea09d4fa059aa4c0550":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b44f17bbfcb94e5da8d24ca845c5c9b4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"eee11cb6a4664b94b8097a46a2a79dbe":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"7b3c866abb5847579852ba1bac610c20":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"2d7893dc076440d6984eca4565e2f6a8":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"63820311ddba46058a21e38b3ec2411f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ef8368aee1934a319d9bec718697a2be":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"6081c5f0abb245659673f76827e89335":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_5942abd915684efbbc317dcd56159276","IPY_MODEL_163f33b9b652436cb1ce899769c08b53","IPY_MODEL_d4fa19cb85924248b7ad6f814d7b77d0"],"layout":"IPY_MODEL_b27194c970094cd48848450e22592118"}},"5942abd915684efbbc317dcd56159276":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_5075c618026c40a0b3b520d249a6df72","placeholder":"​","style":"IPY_MODEL_8244378f753941a4ad8fb6c504ad819e","value":"Downloading (…)lve/main/config.json: 100%"}},"163f33b9b652436cb1ce899769c08b53":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_ca98ba6ccab74f33bdbe1c3a742854ba","max":570,"min":0,"orientation":"horizontal","style":"IPY_MODEL_5e38db9951074f89969fac7b1c25069b","value":570}},"d4fa19cb85924248b7ad6f814d7b77d0":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f22997b7add54b3d86a2bf64808a4b8a","placeholder":"​","style":"IPY_MODEL_48d0ff28190041408f623a174818f5d6","value":" 570/570 [00:00&lt;00:00, 9.54kB/s]"}},"b27194c970094cd48848450e22592118":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5075c618026c40a0b3b520d249a6df72":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8244378f753941a4ad8fb6c504ad819e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"ca98ba6ccab74f33bdbe1c3a742854ba":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5e38db9951074f89969fac7b1c25069b":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f22997b7add54b3d86a2bf64808a4b8a":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"48d0ff28190041408f623a174818f5d6":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"8d34cf6df5a44eb7b251bc5f89e73de2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_ce75700da8fd49bea41eba531a6734a2","IPY_MODEL_f1eb0406447742429e5f9316b837ce13","IPY_MODEL_0eb1c9cec8e1497c93ae7e9ac3fa84bf"],"layout":"IPY_MODEL_026c2293cd2e421a892d04e546296f23"}},"ce75700da8fd49bea41eba531a6734a2":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d240da6dd931453f825cd9a0bb8f4dd2","placeholder":"​","style":"IPY_MODEL_ee5d9610fe5844458b716041d0a77672","value":"Downloading pytorch_model.bin: 100%"}},"f1eb0406447742429e5f9316b837ce13":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_d39caea044ea451f8d9349c66fcca09e","max":440473133,"min":0,"orientation":"horizontal","style":"IPY_MODEL_66479f687cd7452db62a59e553ef8e33","value":440473133}},"0eb1c9cec8e1497c93ae7e9ac3fa84bf":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_fd66c47294ad4ae3a66c820a134a235c","placeholder":"​","style":"IPY_MODEL_5bd8095b743e40a895da8d98f4d15491","value":" 440M/440M [00:02&lt;00:00, 194MB/s]"}},"026c2293cd2e421a892d04e546296f23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d240da6dd931453f825cd9a0bb8f4dd2":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"ee5d9610fe5844458b716041d0a77672":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"d39caea044ea451f8d9349c66fcca09e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"66479f687cd7452db62a59e553ef8e33":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"fd66c47294ad4ae3a66c820a134a235c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5bd8095b743e40a895da8d98f4d15491":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"28c85acd45ef483494a80a3b48591fa3":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_e4cf363e498a4c249b9d9ffc6fce58b5","IPY_MODEL_3ac068f1cc154c3fb676c6c8f51dd906","IPY_MODEL_a1b68284f6b34a46b3808e6694884d19"],"layout":"IPY_MODEL_48f017766a14467bb938504e94de4b6c"}},"e4cf363e498a4c249b9d9ffc6fce58b5":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8ad38b0c7c1046b596771cfdd4c07172","placeholder":"​","style":"IPY_MODEL_5d2311c94c994dccb7496629a1b1ca53","value":"Downloading (…)olve/main/vocab.json: 100%"}},"3ac068f1cc154c3fb676c6c8f51dd906":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_cfc8a6a7ab3c4fae9af3dde51b6b586d","max":898823,"min":0,"orientation":"horizontal","style":"IPY_MODEL_cb8d34b95b4b477287cf1b625079f70f","value":898823}},"a1b68284f6b34a46b3808e6694884d19":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_d60db0da02c949839dd5b3d633eeba23","placeholder":"​","style":"IPY_MODEL_46ddbf3d87a746b89843e74c443b0aba","value":" 899k/899k [00:00&lt;00:00, 9.44MB/s]"}},"48f017766a14467bb938504e94de4b6c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8ad38b0c7c1046b596771cfdd4c07172":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"5d2311c94c994dccb7496629a1b1ca53":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"cfc8a6a7ab3c4fae9af3dde51b6b586d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"cb8d34b95b4b477287cf1b625079f70f":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"d60db0da02c949839dd5b3d633eeba23":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"46ddbf3d87a746b89843e74c443b0aba":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"aba597ece797419ca111f6a0cb4834a2":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_38f8c4f2485845ce996b09932c824aa7","IPY_MODEL_d7055f415a1146b0931c9480b769f540","IPY_MODEL_1d8bb48c048c400c9a2203d7d87295e7"],"layout":"IPY_MODEL_1a3efd38952a4c13afdbe6ecacf5b340"}},"38f8c4f2485845ce996b09932c824aa7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_8fe41b72eb894993a98069c803b0c6f1","placeholder":"​","style":"IPY_MODEL_6795332271da4fd2885079b15dd7fd3c","value":"Downloading (…)olve/main/merges.txt: 100%"}},"d7055f415a1146b0931c9480b769f540":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_26e00d356a164f85a5bf188d5acfd640","max":456318,"min":0,"orientation":"horizontal","style":"IPY_MODEL_7196461d2fe741008de299a17ba84a4e","value":456318}},"1d8bb48c048c400c9a2203d7d87295e7":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_f49007edf72145ea9da29b4b6df99124","placeholder":"​","style":"IPY_MODEL_7be512ac48ba48d3880559bb9e07e906","value":" 456k/456k [00:00&lt;00:00, 11.1MB/s]"}},"1a3efd38952a4c13afdbe6ecacf5b340":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"8fe41b72eb894993a98069c803b0c6f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"6795332271da4fd2885079b15dd7fd3c":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"26e00d356a164f85a5bf188d5acfd640":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7196461d2fe741008de299a17ba84a4e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"f49007edf72145ea9da29b4b6df99124":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"7be512ac48ba48d3880559bb9e07e906":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"a0f5c474ef3c4ef3beb04ed821026076":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d712329025e94029bcc0f472bfc3d881","IPY_MODEL_3efac100e02c4a129c00287f94cc3cdc","IPY_MODEL_170312ec76cd4f3291743276c65de800"],"layout":"IPY_MODEL_0d6742694b444cbc8fd86f33771298af"}},"d712329025e94029bcc0f472bfc3d881":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_70ad8983d0ef48238c465c666455c4c0","placeholder":"​","style":"IPY_MODEL_bc21ed603f94406e9d916d9260f2bc22","value":"Downloading (…)lve/main/config.json: 100%"}},"3efac100e02c4a129c00287f94cc3cdc":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_4bea91231e7849c8a2cf3913b94691f1","max":481,"min":0,"orientation":"horizontal","style":"IPY_MODEL_e2a9f2c887c749d19b873c5700a16b71","value":481}},"170312ec76cd4f3291743276c65de800":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","model_module_version":"1.5.0","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_c7f48b6088164562b2238b70a7c1e0e0","placeholder":"​","style":"IPY_MODEL_75874fa7bf034ad29714653370735bef","value":" 481/481 [00:00&lt;00:00, 36.2kB/s]"}},"0d6742694b444cbc8fd86f33771298af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"70ad8983d0ef48238c465c666455c4c0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"bc21ed603f94406e9d916d9260f2bc22":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"4bea91231e7849c8a2cf3913b94691f1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"e2a9f2c887c749d19b873c5700a16b71":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"c7f48b6088164562b2238b70a7c1e0e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","model_module_version":"1.2.0","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"75874fa7bf034ad29714653370735bef":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","model_module_version":"1.5.0","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}}}}},"nbformat":4,"nbformat_minor":0}